{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fac1</th>\n",
       "      <th>fac2</th>\n",
       "      <th>fac3</th>\n",
       "      <th>fac4</th>\n",
       "      <th>fac5</th>\n",
       "      <th>fac6</th>\n",
       "      <th>fac7</th>\n",
       "      <th>fac8</th>\n",
       "      <th>fac9</th>\n",
       "      <th>fac10</th>\n",
       "      <th>...</th>\n",
       "      <th>fac26</th>\n",
       "      <th>fac27</th>\n",
       "      <th>fac28</th>\n",
       "      <th>fac29</th>\n",
       "      <th>fac30</th>\n",
       "      <th>fac31</th>\n",
       "      <th>fac32</th>\n",
       "      <th>fac33</th>\n",
       "      <th>long return</th>\n",
       "      <th>short return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.019506</td>\n",
       "      <td>-0.555555</td>\n",
       "      <td>-0.044372</td>\n",
       "      <td>-0.006845</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.017698</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>-0.005437</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>-0.002507</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.132730</td>\n",
       "      <td>-0.830189</td>\n",
       "      <td>-0.068396</td>\n",
       "      <td>-0.011363</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.016692</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048544</td>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000296</td>\n",
       "      <td>-0.017991</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.067358</td>\n",
       "      <td>-0.010600</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.016580</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>-0.005237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>-0.002493</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.021552</td>\n",
       "      <td>-0.517241</td>\n",
       "      <td>-0.046512</td>\n",
       "      <td>-0.010224</td>\n",
       "      <td>0.007456</td>\n",
       "      <td>0.016282</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>-0.005729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>-0.002485</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.055639</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.056485</td>\n",
       "      <td>-0.011385</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>-0.005393</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.070707</td>\n",
       "      <td>-0.002460</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74345</th>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.333332</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.002180</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>-0.004290</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74346</th>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-0.002074</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>-0.004131</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74347</th>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>-0.003815</td>\n",
       "      <td>-0.006258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74348</th>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74349</th>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>-0.001818</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74350 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fac1      fac2      fac3      fac4      fac5      fac6      fac7  \\\n",
       "0     -0.000214 -0.019506 -0.555555 -0.044372 -0.006845  0.012014  0.017698   \n",
       "1     -0.000292 -0.132730 -0.830189 -0.068396 -0.011363  0.008915  0.016692   \n",
       "2     -0.000296 -0.017991 -0.999999 -0.067358 -0.010600  0.007809  0.016580   \n",
       "3     -0.000290 -0.021552 -0.517241 -0.046512 -0.010224  0.007456  0.016282   \n",
       "4     -0.000322 -0.055639 -1.000000 -0.056485 -0.011385  0.006608  0.015556   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "74345 -0.000054  0.001085  0.333332  0.000816 -0.002180  0.000699  0.004050   \n",
       "74346 -0.000054 -0.001086 -0.999990  0.000815 -0.002074  0.000458  0.004056   \n",
       "74347 -0.000054 -0.001085 -0.999990  0.000271 -0.001803  0.000459  0.004125   \n",
       "74348 -0.000053  0.004329  0.999998  0.000813  0.000382  0.007821  0.004176   \n",
       "74349 -0.000053 -0.001081 -0.999990  0.000271  0.000273  0.007250  0.004165   \n",
       "\n",
       "           fac8      fac9  fac10  ...  fac26     fac27     fac28     fac29  \\\n",
       "0      0.005543 -0.005437    3.0  ...    0.0 -0.028571 -0.002507  0.000537   \n",
       "1      0.004849 -0.005456    2.0  ...    0.0 -0.048544 -0.002496  0.000523   \n",
       "2      0.004801 -0.005237    0.0  ...    0.0 -0.039216 -0.002493  0.000523   \n",
       "3      0.004631 -0.005729    0.0  ...    0.0 -0.049505 -0.002485  0.000524   \n",
       "4      0.004362 -0.005393   -1.0  ...    0.0 -0.070707 -0.002460  0.000521   \n",
       "...         ...       ...    ...  ...    ...       ...       ...       ...   \n",
       "74345 -0.004290 -0.006255    0.0  ...   -0.0 -0.333333 -0.000835  0.000040   \n",
       "74346 -0.004131 -0.006255    0.0  ...   -0.0 -0.333333 -0.000835  0.000044   \n",
       "74347 -0.003815 -0.006258    0.0  ...   -0.0 -0.333333 -0.000835  0.000053   \n",
       "74348 -0.002501 -0.006255    1.0  ...    0.0 -0.333333 -0.000835  0.000134   \n",
       "74349 -0.001818 -0.006255    0.0  ...    0.0 -0.333333 -0.000834  0.000134   \n",
       "\n",
       "          fac30     fac31     fac32     fac33  long return  short return  \n",
       "0      0.000537  0.000493  0.000235  0.000121     0.000647           0.0  \n",
       "1      0.000523  0.000471  0.000226  0.000183     0.000647           0.0  \n",
       "2      0.000523  0.000468  0.000250  0.000201     0.000647           0.0  \n",
       "3      0.000524  0.000468  0.000250  0.000234     0.000647           0.0  \n",
       "4      0.000521  0.000463  0.000249  0.000224     0.000647           0.0  \n",
       "...         ...       ...       ...       ...          ...           ...  \n",
       "74345  0.000040  0.000171  0.000224  0.000326     0.000000           0.0  \n",
       "74346  0.000044  0.000171  0.000223  0.000326     0.000000           0.0  \n",
       "74347  0.000053  0.000171  0.000223  0.000326     0.000000           0.0  \n",
       "74348  0.000134  0.000169  0.000036  0.000109     0.000000           0.0  \n",
       "74349  0.000134  0.000169  0.000024  0.000000     0.000000           0.0  \n",
       "\n",
       "[74350 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('level2_i_20221201.csv')\n",
    "df.head()\n",
    "\n",
    "long = 100\n",
    "short = 50\n",
    "\n",
    "\n",
    "a = df['midp'].diff(long) / df['midp'].shift(long)\n",
    "a = a.dropna()\n",
    "a.reset_index(drop = True, inplace = True)\n",
    "df['long return'] = a\n",
    "\n",
    "b = df['midp'].diff(short) / df['midp'].shift(short)\n",
    "b = b.dropna()\n",
    "b.reset_index(drop = True, inplace = True)\n",
    "df['short return'] = b\n",
    "\n",
    "col_reserved = ['fac{}'.format(i) for i in range(1, 34)]\n",
    "col_reserved.append('long return')\n",
    "col_reserved.append('short return')\n",
    "\n",
    "new_df = df[col_reserved]\n",
    "linear_df = new_df[1200:-1200]\n",
    "#linear_df.fillna(0, inplace = True)\n",
    "linear_df.reset_index(drop = True, inplace = True)\n",
    "linear_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1000\n",
      "R_square_short = -0.021124898257484537\n",
      "R_square_long = -0.004558564444085311\n",
      "i = 2000\n",
      "R_square_short = -0.002780730167261325\n",
      "R_square_long = -0.026504659613841852\n",
      "i = 3000\n",
      "R_square_short = -0.0026176814159806217\n",
      "R_square_long = -0.033327054627172004\n",
      "i = 4000\n",
      "R_square_short = -0.00012668570031348914\n",
      "R_square_long = -0.009613707095719848\n",
      "i = 5000\n",
      "R_square_short = -2.298392365318591e-08\n",
      "R_square_long = -0.014743529921542153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 6000\n",
      "R_square_short = -0.008503021487249685\n",
      "R_square_long = -7.094401321072752e-06\n",
      "i = 7000\n",
      "R_square_short = -0.016600948996362552\n",
      "R_square_long = -0.016730755889752924\n",
      "i = 8000\n",
      "R_square_short = -0.026709401709401615\n",
      "R_square_long = -0.10303307422649044\n",
      "i = 9000\n",
      "R_square_short = -0.0011170023131301665\n",
      "R_square_long = -0.01615884395048628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "window_size = 500\n",
    "\n",
    "predict_long = []\n",
    "predict_short = []\n",
    "# this sequence record the R square of validation set\n",
    "R_square_long = []\n",
    "R_square_short = []\n",
    "\n",
    "#limit = len(linear_df)\n",
    "limit = 10000\n",
    "\n",
    "for i in range(window_size, limit):\n",
    "    train_X = linear_df.iloc[i - window_size : i - 200, :-2]\n",
    "    train_y_long = linear_df.iloc[i - window_size : i - 200, -2]\n",
    "    train_y_short = linear_df.iloc[i - window_size : i - 200, -1]\n",
    "    # split the train set into train set and validation set by order \n",
    "    train_X_long, validate_X_long, train_y_long, validate_y_long = train_test_split(train_X, train_y_long, test_size = 0.1, random_state = 11)\n",
    "    train_X_short, validate_X_short, train_y_short, validate_y_short = train_test_split(train_X, train_y_short, test_size = 0.1, random_state = 11)\n",
    "\n",
    "    test_X = linear_df.iloc[i:i+1, :-2]\n",
    "    test_y_long = np.array(linear_df.iloc[i, -2]).reshape(1, -1)\n",
    "    test_y_short = np.array(linear_df.iloc[i, -1]).reshape(1, -1)\n",
    "\n",
    "    #model_short = LinearRegression()\n",
    "    #model_long = LinearRegression()\n",
    "\n",
    "    model_long = Lasso(alpha = 0.1)\n",
    "    model_short = Lasso(alpha = 0.1)\n",
    "    \n",
    "    scaler_short = StandardScaler()\n",
    "    scaler_long = StandardScaler()\n",
    "\n",
    "    scaled_train_X_short = scaler_short.fit_transform(train_X_short)\n",
    "    scaled_validate_X_short = scaler_short.transform(validate_X_short)\n",
    "    scaled_test_X_short = scaler_short.transform(test_X)\n",
    "\n",
    "    scaled_train_X_long = scaler_long.fit_transform(train_X_long)\n",
    "    scaled_validate_X_long = scaler_long.transform(validate_X_long)\n",
    "    scaled_test_X_long = scaler_long.transform(test_X)\n",
    "\n",
    "    model_short.fit(scaled_train_X_short, train_y_short)\n",
    "    model_long.fit(scaled_train_X_long, train_y_long)\n",
    "\n",
    "    predict_short.append(model_short.predict(scaled_test_X_short))\n",
    "    predict_long.append(model_long.predict(scaled_test_X_long))\n",
    "\n",
    "    R_square_short.append(model_short.score(scaled_validate_X_short, validate_y_short))\n",
    "    R_square_long.append(model_long.score(scaled_validate_X_long, validate_y_long))\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print('i = {}'.format(i))\n",
    "        print('R_square_short = {}'.format(model_short.score(scaled_validate_X_short, validate_y_short)))\n",
    "        print('R_square_long = {}'.format(model_long.score(scaled_validate_X_long, validate_y_long)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_short = np.array(predict_short).reshape(-1)\n",
    "predict_long = np.array(predict_long).reshape(-1)\n",
    "R_square_short = np.array(R_square_short).reshape(-1)\n",
    "R_square_long = np.array(R_square_long).reshape(-1)\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "new_df['predict_short'] = predict_short\n",
    "new_df['predict_long'] = predict_long\n",
    "new_df['R_square_short'] = R_square_short\n",
    "new_df['R_square_long'] = R_square_long\n",
    "\n",
    "new_df['long return'] = linear_df['long return'].iloc[window_size:limit].reset_index(drop = True)\n",
    "new_df['short return'] = linear_df['short return'].iloc[window_size:limit].reset_index(drop = True)\n",
    "\n",
    "new_df['predict_long_sign'] = new_df['predict_long'].apply(lambda x: 1 if x > 0 else 0 if x == 0 else -1)\n",
    "new_df['predict_short_sign'] = new_df['predict_short'].apply(lambda x: 1 if x > 0 else 0 if x == 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    predict_short_sign  short return\n",
      "predict_short_sign            1.000000      0.121923\n",
      "short return                  0.121923      1.000000\n",
      "                   predict_long_sign  long return\n",
      "predict_long_sign           1.000000     0.151713\n",
      "long return                 0.151713     1.000000\n",
      "               predict_short  short return\n",
      "predict_short       1.000000      0.089821\n",
      "short return        0.089821      1.000000\n",
      "              predict_long  long return\n",
      "predict_long      1.000000     0.114448\n",
      "long return       0.114448     1.000000\n"
     ]
    }
   ],
   "source": [
    "print(new_df[['predict_short_sign', 'short return']].corr())\n",
    "print(new_df[['predict_long_sign', 'long return']].corr())\n",
    "print(new_df[['predict_short', 'short return']].corr())\n",
    "print(new_df[['predict_long', 'long return']].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1000\n",
      "R_square_short = 0.936636784374368\n",
      "R_square_long = 0.8843583233664812\n",
      "i = 2000\n",
      "R_square_short = 0.6966938926430768\n",
      "R_square_long = 0.8974168458286829\n",
      "i = 3000\n",
      "R_square_short = 0.61595980712705\n",
      "R_square_long = 0.7485888081074434\n",
      "i = 4000\n",
      "R_square_short = 0.844677501323146\n",
      "R_square_long = 0.9697336926870302\n",
      "i = 5000\n",
      "R_square_short = 0.8344372858285898\n",
      "R_square_long = 0.9690888107999847\n",
      "i = 6000\n",
      "R_square_short = 0.8415767414332094\n",
      "R_square_long = 0.9884390235810417\n",
      "i = 7000\n",
      "R_square_short = 0.8272150165587098\n",
      "R_square_long = 0.8874160951862159\n",
      "i = 8000\n",
      "R_square_short = 0.6202930169995982\n",
      "R_square_long = 0.09600196630833524\n",
      "i = 9000\n",
      "R_square_short = 0.856828637134442\n",
      "R_square_long = 0.9212180507718367\n"
     ]
    }
   ],
   "source": [
    "a = df['midp'].diff(long) / df['midp'].shift(long)\n",
    "a = a.dropna()\n",
    "a.reset_index(drop = True, inplace = True)\n",
    "df['long return'] = a\n",
    "\n",
    "b = df['midp'].diff(short) / df['midp'].shift(short)\n",
    "b = b.dropna()\n",
    "b.reset_index(drop = True, inplace = True)\n",
    "df['short return'] = b\n",
    "\n",
    "col_reserved = ['fac{}'.format(i) for i in range(1, 34)]\n",
    "col_reserved.append('long return')\n",
    "col_reserved.append('short return')\n",
    "\n",
    "new_df = df[col_reserved]\n",
    "linear_df = new_df[1200:-1200]\n",
    "#linear_df.fillna(0, inplace = True)\n",
    "linear_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "predict_long = []\n",
    "predict_short = []\n",
    "# this sequence record the R square of validation set\n",
    "R_square_long = []\n",
    "R_square_short = []\n",
    "\n",
    "for i in range(window_size, limit):\n",
    "    train_X = linear_df.iloc[i - window_size : i - 200, :-2]\n",
    "    train_y_long = linear_df.iloc[i - window_size : i - 200, -2]\n",
    "    train_y_short = linear_df.iloc[i - window_size : i - 200, -1]\n",
    "\n",
    "    train_X_long, validate_X_long, train_y_long, validate_y_long = train_test_split(train_X, train_y_long, test_size = 0.1, random_state = 11)\n",
    "    train_X_short, validate_X_short, train_y_short, validate_y_short = train_test_split(train_X, train_y_short, test_size = 0.1, random_state = 11)\n",
    "\n",
    "    test_X = linear_df.iloc[i:i+1, :-2]\n",
    "    test_y_long = np.array(linear_df.iloc[i, -2]).reshape(1, -1)\n",
    "    test_y_short = np.array(linear_df.iloc[i, -1]).reshape(1, -1)\n",
    "\n",
    "    #model_short = LinearRegression()\n",
    "    #model_long = LinearRegression()\n",
    "\n",
    "    model_long = Ridge(alpha = 0.1)\n",
    "    model_short = Ridge(alpha = 0.1)\n",
    "    \n",
    "    scaler_short = StandardScaler()\n",
    "    scaler_long = StandardScaler()\n",
    "\n",
    "    scaled_train_X_short = scaler_short.fit_transform(train_X_short)\n",
    "    scaled_validate_X_short = scaler_short.transform(validate_X_short)\n",
    "    scaled_test_X_short = scaler_short.transform(test_X)\n",
    "\n",
    "    scaled_train_X_long = scaler_long.fit_transform(train_X_long)\n",
    "    scaled_validate_X_long = scaler_long.transform(validate_X_long)\n",
    "    scaled_test_X_long = scaler_long.transform(test_X)\n",
    "\n",
    "    model_short.fit(scaled_train_X_short, train_y_short)\n",
    "    model_long.fit(scaled_train_X_long, train_y_long)\n",
    "\n",
    "    predict_short.append(model_short.predict(scaled_test_X_short))\n",
    "    predict_long.append(model_long.predict(scaled_test_X_long))\n",
    "\n",
    "    R_square_short.append(model_short.score(scaled_validate_X_short, validate_y_short))\n",
    "    R_square_long.append(model_long.score(scaled_validate_X_long, validate_y_long))\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print('i = {}'.format(i))\n",
    "        print('R_square_short = {}'.format(model_short.score(scaled_validate_X_short, validate_y_short)))\n",
    "        print('R_square_long = {}'.format(model_long.score(scaled_validate_X_long, validate_y_long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_square_short = np.array(R_square_short).reshape(-1)\n",
    "R_square_long = np.array(R_square_long).reshape(-1)\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "new_df['predict_short'] = predict_short\n",
    "new_df['predict_long'] = predict_long\n",
    "new_df['R_square_short'] = R_square_short\n",
    "new_df['R_square_long'] = R_square_long\n",
    "\n",
    "new_df['long return'] = linear_df['long return'].iloc[window_size:limit].reset_index(drop = True)\n",
    "new_df['short return'] = linear_df['short return'].iloc[window_size:limit].reset_index(drop = True)\n",
    "new_df['predict_long_sign'] = new_df['predict_long'].apply(lambda x: 1 if x > 0 else 0 if x == 0 else -1)\n",
    "new_df['predict_short_sign'] = new_df['predict_short'].apply(lambda x: 1 if x > 0 else 0 if x == 0 else -1)\n",
    "new_dfpredict_short = np.array(predict_short).reshape(-1)\n",
    "predict_long = np.array(predict_long).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    predict_short_sign  short return\n",
      "predict_short_sign            1.000000      0.063666\n",
      "short return                  0.063666      1.000000\n",
      "                   predict_long_sign  long return\n",
      "predict_long_sign           1.000000     0.100886\n",
      "long return                 0.100886     1.000000\n",
      "              short return\n",
      "short return           1.0\n",
      "             long return\n",
      "long return          1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_5380\\3606610826.py:3: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  print(new_df[['predict_short', 'short return']].corr())\n",
      "C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_5380\\3606610826.py:4: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  print(new_df[['predict_long', 'long return']].corr())\n"
     ]
    }
   ],
   "source": [
    "print(new_df[['predict_short_sign', 'short return']].corr())\n",
    "print(new_df[['predict_long_sign', 'long return']].corr())\n",
    "print(new_df[['predict_short', 'short return']].corr())\n",
    "print(new_df[['predict_long', 'long return']].corr())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qids-2023-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
